#
# Copyright (C) [2020] Futurewei Technologies, Inc.
#
# FORCE-RISCV is licensed under the Apache License, Version 2.0
#  (the "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES
# OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
# NON-INFRINGEMENT, MERCHANTABILITY OR FIT FOR A PARTICULAR PURPOSE.
# See the License for the specific language governing permissions and
# limitations under the License.
#
from base.InstructionMap import InstructionMap

# Utility function used to combine multiple dictionaries into one 

def merge(*args):
    result = {}
    for dict1 in args:
        result.update(dict1)
    return result

vconfig_instructions = {
    "VSETVL##RISCV": 10,
    "VSETVLI##RISCV": 10,
    "VSETIVLI##RISCV": 10,    
}

vconfig_map = InstructionMap("vconfig_instructions", vconfig_instructions)

# v-ldst has 310 insts in total under V-SPEC V1.0
vldst_instructions = {
    "VL1RE16.V##RISCV"      :10,  
    "VL1RE32.V##RISCV"      :10,  
    "VL1RE64.V##RISCV"      :10,  
    "VL1RE8.V##RISCV"       :10,  
    "VL2RE16.V##RISCV"      :10,  
    "VL2RE32.V##RISCV"      :10,  
    "VL2RE64.V##RISCV"      :10,  
    "VL2RE8.V##RISCV"       :10,  
    "VL4RE16.V##RISCV"      :10,  
    "VL4RE32.V##RISCV"      :10,  
    "VL4RE64.V##RISCV"      :10,  
    "VL4RE8.V##RISCV"       :10,  
    "VL8RE16.V##RISCV"      :10,  
    "VL8RE32.V##RISCV"      :10,  
    "VL8RE64.V##RISCV"      :10,  
    "VL8RE8.V##RISCV"       :10,  
    "VLE16.V##RISCV"        :10,  
    "VLE16FF.V##RISCV"      :10,  
    "VLE32.V##RISCV"        :10,  
    "VLE32FF.V##RISCV"      :10,  
    "VLE64.V##RISCV"        :10,  
    "VLE64FF.V##RISCV"      :10,  
    "VLE8.V##RISCV"         :10,  
    "VLE8FF.V##RISCV"       :10,  
    "VLM.V##RISCV"          :10,  
    "VLOXEI16.V##RISCV"     :10,  
    "VLOXEI32.V##RISCV"     :10,  
    "VLOXEI64.V##RISCV"     :10,  
    "VLOXEI8.V##RISCV"      :10,  
    "VLOXSEG2EI16.V##RISCV" :10,  
    "VLOXSEG2EI32.V##RISCV" :10,  
    "VLOXSEG2EI64.V##RISCV" :10,  
    "VLOXSEG2EI8.V##RISCV"  :10,  
    "VLOXSEG3EI16.V##RISCV" :10,  
    "VLOXSEG3EI32.V##RISCV" :10,  
    "VLOXSEG3EI64.V##RISCV" :10,  
    "VLOXSEG3EI8.V##RISCV"  :10,  
    "VLOXSEG4EI16.V##RISCV" :10,  
    "VLOXSEG4EI32.V##RISCV" :10,  
    "VLOXSEG4EI64.V##RISCV" :10,  
    "VLOXSEG4EI8.V##RISCV"  :10,  
    "VLOXSEG5EI16.V##RISCV" :10,  
    "VLOXSEG5EI32.V##RISCV" :10,  
    "VLOXSEG5EI64.V##RISCV" :10,  
    "VLOXSEG5EI8.V##RISCV"  :10,  
    "VLOXSEG6EI16.V##RISCV" :10,  
    "VLOXSEG6EI32.V##RISCV" :10,  
    "VLOXSEG6EI64.V##RISCV" :10,  
    "VLOXSEG6EI8.V##RISCV"  :10,  
    "VLOXSEG7EI16.V##RISCV" :10,  
    "VLOXSEG7EI32.V##RISCV" :10,  
    "VLOXSEG7EI64.V##RISCV" :10,  
    "VLOXSEG7EI8.V##RISCV"  :10,  
    "VLOXSEG8EI16.V##RISCV" :10,  
    "VLOXSEG8EI32.V##RISCV" :10,  
    "VLOXSEG8EI64.V##RISCV" :10,  
    "VLOXSEG8EI8.V##RISCV"  :10,  
    "VLSE16.V##RISCV"       :10,  
    "VLSE32.V##RISCV"       :10,  
    "VLSE64.V##RISCV"       :10,  
    "VLSE8.V##RISCV"        :10,  
    "VLSEG2E16.V##RISCV"    :10,  
    "VLSEG2E16FF.V##RISCV"  :10,  
    "VLSEG2E32.V##RISCV"    :10,  
    "VLSEG2E32FF.V##RISCV"  :10,  
    "VLSEG2E64.V##RISCV"    :10,  
    "VLSEG2E64FF.V##RISCV"  :10,  
    "VLSEG2E8.V##RISCV"     :10,  
    "VLSEG2E8FF.V##RISCV"   :10,  
    "VLSEG3E16.V##RISCV"    :10,  
    "VLSEG3E16FF.V##RISCV"  :10,  
    "VLSEG3E32.V##RISCV"    :10,  
    "VLSEG3E32FF.V##RISCV"  :10,  
    "VLSEG3E64.V##RISCV"    :10,  
    "VLSEG3E64FF.V##RISCV"  :10,  
    "VLSEG3E8.V##RISCV"     :10,  
    "VLSEG3E8FF.V##RISCV"   :10,  
    "VLSEG4E16.V##RISCV"    :10,  
    "VLSEG4E16FF.V##RISCV"  :10,  
    "VLSEG4E32.V##RISCV"    :10,  
    "VLSEG4E32FF.V##RISCV"  :10,  
    "VLSEG4E64.V##RISCV"    :10,  
    "VLSEG4E64FF.V##RISCV"  :10,  
    "VLSEG4E8.V##RISCV"     :10,  
    "VLSEG4E8FF.V##RISCV"   :10,  
    "VLSEG5E16.V##RISCV"    :10,  
    "VLSEG5E16FF.V##RISCV"  :10,  
    "VLSEG5E32.V##RISCV"    :10,  
    "VLSEG5E32FF.V##RISCV"  :10,  
    "VLSEG5E64.V##RISCV"    :10,  
    "VLSEG5E64FF.V##RISCV"  :10,  
    "VLSEG5E8.V##RISCV"     :10,  
    "VLSEG5E8FF.V##RISCV"   :10,  
    "VLSEG6E16.V##RISCV"    :10,  
    "VLSEG6E16FF.V##RISCV"  :10,  
    "VLSEG6E32.V##RISCV"    :10,  
    "VLSEG6E32FF.V##RISCV"  :10,  
    "VLSEG6E64.V##RISCV"    :10,  
    "VLSEG6E64FF.V##RISCV"  :10,  
    "VLSEG6E8.V##RISCV"     :10,  
    "VLSEG6E8FF.V##RISCV"   :10,  
    "VLSEG7E16.V##RISCV"    :10,  
    "VLSEG7E16FF.V##RISCV"  :10,  
    "VLSEG7E32.V##RISCV"    :10,  
    "VLSEG7E32FF.V##RISCV"  :10,  
    "VLSEG7E64.V##RISCV"    :10,  
    "VLSEG7E64FF.V##RISCV"  :10,  
    "VLSEG7E8.V##RISCV"     :10,  
    "VLSEG7E8FF.V##RISCV"   :10,  
    "VLSEG8E16.V##RISCV"    :10,  
    "VLSEG8E16FF.V##RISCV"  :10,  
    "VLSEG8E32.V##RISCV"    :10,  
    "VLSEG8E32FF.V##RISCV"  :10,  
    "VLSEG8E64.V##RISCV"    :10,  
    "VLSEG8E64FF.V##RISCV"  :10,  
    "VLSEG8E8.V##RISCV"     :10,  
    "VLSEG8E8FF.V##RISCV"   :10,  
    "VLSSEG2E16.V##RISCV"   :10,  
    "VLSSEG2E32.V##RISCV"   :10,  
    "VLSSEG2E64.V##RISCV"   :10,  
    "VLSSEG2E8.V##RISCV"    :10,  
    "VLSSEG3E16.V##RISCV"   :10,  
    "VLSSEG3E32.V##RISCV"   :10,  
    "VLSSEG3E64.V##RISCV"   :10,  
    "VLSSEG3E8.V##RISCV"    :10,  
    "VLSSEG4E16.V##RISCV"   :10,  
    "VLSSEG4E32.V##RISCV"   :10,  
    "VLSSEG4E64.V##RISCV"   :10,  
    "VLSSEG4E8.V##RISCV"    :10,  
    "VLSSEG5E16.V##RISCV"   :10,  
    "VLSSEG5E32.V##RISCV"   :10,  
    "VLSSEG5E64.V##RISCV"   :10,  
    "VLSSEG5E8.V##RISCV"    :10,  
    "VLSSEG6E16.V##RISCV"   :10,  
    "VLSSEG6E32.V##RISCV"   :10,  
    "VLSSEG6E64.V##RISCV"   :10,  
    "VLSSEG6E8.V##RISCV"    :10,  
    "VLSSEG7E16.V##RISCV"   :10,  
    "VLSSEG7E32.V##RISCV"   :10,  
    "VLSSEG7E64.V##RISCV"   :10,  
    "VLSSEG7E8.V##RISCV"    :10,  
    "VLSSEG8E16.V##RISCV"   :10,  
    "VLSSEG8E32.V##RISCV"   :10,  
    "VLSSEG8E64.V##RISCV"   :10,  
    "VLSSEG8E8.V##RISCV"    :10,  
    "VLUXEI16.V##RISCV"     :10,  
    "VLUXEI32.V##RISCV"     :10,  
    "VLUXEI64.V##RISCV"     :10,  
    "VLUXEI8.V##RISCV"      :10,  
    "VLUXSEG2EI16.V##RISCV" :10,  
    "VLUXSEG2EI32.V##RISCV" :10,  
    "VLUXSEG2EI64.V##RISCV" :10,  
    "VLUXSEG2EI8.V##RISCV"  :10,  
    "VLUXSEG3EI16.V##RISCV" :10,  
    "VLUXSEG3EI32.V##RISCV" :10,  
    "VLUXSEG3EI64.V##RISCV" :10,  
    "VLUXSEG3EI8.V##RISCV"  :10,  
    "VLUXSEG4EI16.V##RISCV" :10,  
    "VLUXSEG4EI32.V##RISCV" :10,  
    "VLUXSEG4EI64.V##RISCV" :10,  
    "VLUXSEG4EI8.V##RISCV"  :10,  
    "VLUXSEG5EI16.V##RISCV" :10,  
    "VLUXSEG5EI32.V##RISCV" :10,  
    "VLUXSEG5EI64.V##RISCV" :10,  
    "VLUXSEG5EI8.V##RISCV"  :10,  
    "VLUXSEG6EI16.V##RISCV" :10,  
    "VLUXSEG6EI32.V##RISCV" :10,  
    "VLUXSEG6EI64.V##RISCV" :10,  
    "VLUXSEG6EI8.V##RISCV"  :10,  
    "VLUXSEG7EI16.V##RISCV" :10,  
    "VLUXSEG7EI32.V##RISCV" :10,  
    "VLUXSEG7EI64.V##RISCV" :10,  
    "VLUXSEG7EI8.V##RISCV"  :10,  
    "VLUXSEG8EI16.V##RISCV" :10,  
    "VLUXSEG8EI32.V##RISCV" :10,  
    "VLUXSEG8EI64.V##RISCV" :10,  
    "VLUXSEG8EI8.V##RISCV"  :10,  
    "VS1R.V##RISCV"         :10,  
    "VS2R.V##RISCV"         :10,  
    "VS4R.V##RISCV"         :10,  
    "VS8R.V##RISCV"         :10,  
    "VSE16.V##RISCV"        :10,  
    "VSE32.V##RISCV"        :10,  
    "VSE64.V##RISCV"        :10,  
    "VSE8.V##RISCV"         :10,  
    "VSM.V##RISCV"          :10,  
    "VSOXEI16.V##RISCV"     :10,  
    "VSOXEI32.V##RISCV"     :10,  
    "VSOXEI64.V##RISCV"     :10,  
    "VSOXEI8.V##RISCV"      :10,  
    "VSOXSEG2EI16.V##RISCV" :10,  
    "VSOXSEG2EI32.V##RISCV" :10,  
    "VSOXSEG2EI64.V##RISCV" :10,  
    "VSOXSEG2EI8.V##RISCV"  :10,  
    "VSOXSEG3EI16.V##RISCV" :10,  
    "VSOXSEG3EI32.V##RISCV" :10,  
    "VSOXSEG3EI64.V##RISCV" :10,  
    "VSOXSEG3EI8.V##RISCV"  :10,  
    "VSOXSEG4EI16.V##RISCV" :10,  
    "VSOXSEG4EI32.V##RISCV" :10,  
    "VSOXSEG4EI64.V##RISCV" :10,  
    "VSOXSEG4EI8.V##RISCV"  :10,  
    "VSOXSEG5EI16.V##RISCV" :10,  
    "VSOXSEG5EI32.V##RISCV" :10,  
    "VSOXSEG5EI64.V##RISCV" :10,  
    "VSOXSEG5EI8.V##RISCV"  :10,  
    "VSOXSEG6EI16.V##RISCV" :10,  
    "VSOXSEG6EI32.V##RISCV" :10,  
    "VSOXSEG6EI64.V##RISCV" :10,  
    "VSOXSEG6EI8.V##RISCV"  :10,  
    "VSOXSEG7EI16.V##RISCV" :10,  
    "VSOXSEG7EI32.V##RISCV" :10,  
    "VSOXSEG7EI64.V##RISCV" :10,  
    "VSOXSEG7EI8.V##RISCV"  :10,  
    "VSOXSEG8EI16.V##RISCV" :10,  
    "VSOXSEG8EI32.V##RISCV" :10,  
    "VSOXSEG8EI64.V##RISCV" :10,  
    "VSOXSEG8EI8.V##RISCV"  :10,  
    "VSSE16.V##RISCV"       :10,  
    "VSSE32.V##RISCV"       :10,  
    "VSSE64.V##RISCV"       :10,  
    "VSSE8.V##RISCV"        :10,  
    "VSSEG2E16.V##RISCV"    :10,  
    "VSSEG2E32.V##RISCV"    :10,  
    "VSSEG2E64.V##RISCV"    :10,  
    "VSSEG2E8.V##RISCV"     :10,  
    "VSSEG3E16.V##RISCV"    :10,  
    "VSSEG3E32.V##RISCV"    :10,  
    "VSSEG3E64.V##RISCV"    :10,  
    "VSSEG3E8.V##RISCV"     :10,  
    "VSSEG4E16.V##RISCV"    :10,  
    "VSSEG4E32.V##RISCV"    :10,  
    "VSSEG4E64.V##RISCV"    :10,  
    "VSSEG4E8.V##RISCV"     :10,  
    "VSSEG5E16.V##RISCV"    :10,  
    "VSSEG5E32.V##RISCV"    :10,  
    "VSSEG5E64.V##RISCV"    :10,  
    "VSSEG5E8.V##RISCV"     :10,  
    "VSSEG6E16.V##RISCV"    :10,  
    "VSSEG6E32.V##RISCV"    :10,  
    "VSSEG6E64.V##RISCV"    :10,  
    "VSSEG6E8.V##RISCV"     :10,  
    "VSSEG7E16.V##RISCV"    :10,  
    "VSSEG7E32.V##RISCV"    :10,  
    "VSSEG7E64.V##RISCV"    :10,  
    "VSSEG7E8.V##RISCV"     :10,  
    "VSSEG8E16.V##RISCV"    :10,  
    "VSSEG8E32.V##RISCV"    :10,  
    "VSSEG8E64.V##RISCV"    :10,  
    "VSSEG8E8.V##RISCV"     :10,  
    "VSSSEG2E16.V##RISCV"   :10,  
    "VSSSEG2E32.V##RISCV"   :10,  
    "VSSSEG2E64.V##RISCV"   :10,  
    "VSSSEG2E8.V##RISCV"    :10,  
    "VSSSEG3E16.V##RISCV"   :10,  
    "VSSSEG3E32.V##RISCV"   :10,  
    "VSSSEG3E64.V##RISCV"   :10,  
    "VSSSEG3E8.V##RISCV"    :10,  
    "VSSSEG4E16.V##RISCV"   :10,  
    "VSSSEG4E32.V##RISCV"   :10,  
    "VSSSEG4E64.V##RISCV"   :10,  
    "VSSSEG4E8.V##RISCV"    :10,  
    "VSSSEG5E16.V##RISCV"   :10,  
    "VSSSEG5E32.V##RISCV"   :10,  
    "VSSSEG5E64.V##RISCV"   :10,  
    "VSSSEG5E8.V##RISCV"    :10,  
    "VSSSEG6E16.V##RISCV"   :10,  
    "VSSSEG6E32.V##RISCV"   :10,  
    "VSSSEG6E64.V##RISCV"   :10,  
    "VSSSEG6E8.V##RISCV"    :10,  
    "VSSSEG7E16.V##RISCV"   :10,  
    "VSSSEG7E32.V##RISCV"   :10,  
    "VSSSEG7E64.V##RISCV"   :10,  
    "VSSSEG7E8.V##RISCV"    :10,  
    "VSSSEG8E16.V##RISCV"   :10,  
    "VSSSEG8E32.V##RISCV"   :10,  
    "VSSSEG8E64.V##RISCV"   :10,  
    "VSSSEG8E8.V##RISCV"    :10,  
    "VSUXEI16.V##RISCV"     :10,  
    "VSUXEI32.V##RISCV"     :10,  
    "VSUXEI64.V##RISCV"     :10,  
    "VSUXEI8.V##RISCV"      :10,  
    "VSUXSEG2EI16.V##RISCV" :10,  
    "VSUXSEG2EI32.V##RISCV" :10,  
    "VSUXSEG2EI64.V##RISCV" :10,  
    "VSUXSEG2EI8.V##RISCV"  :10,  
    "VSUXSEG3EI16.V##RISCV" :10,  
    "VSUXSEG3EI32.V##RISCV" :10,  
    "VSUXSEG3EI64.V##RISCV" :10,  
    "VSUXSEG3EI8.V##RISCV"  :10,  
    "VSUXSEG4EI16.V##RISCV" :10,  
    "VSUXSEG4EI32.V##RISCV" :10,  
    "VSUXSEG4EI64.V##RISCV" :10,  
    "VSUXSEG4EI8.V##RISCV"  :10,  
    "VSUXSEG5EI16.V##RISCV" :10,  
    "VSUXSEG5EI32.V##RISCV" :10,  
    "VSUXSEG5EI64.V##RISCV" :10,  
    "VSUXSEG5EI8.V##RISCV"  :10,  
    "VSUXSEG6EI16.V##RISCV" :10,  
    "VSUXSEG6EI32.V##RISCV" :10,  
    "VSUXSEG6EI64.V##RISCV" :10,  
    "VSUXSEG6EI8.V##RISCV"  :10,  
    "VSUXSEG7EI16.V##RISCV" :10,  
    "VSUXSEG7EI32.V##RISCV" :10,  
    "VSUXSEG7EI64.V##RISCV" :10,  
    "VSUXSEG7EI8.V##RISCV"  :10,  
    "VSUXSEG8EI16.V##RISCV" :10,  
    "VSUXSEG8EI32.V##RISCV" :10,  
    "VSUXSEG8EI64.V##RISCV" :10,  
    "VSUXSEG8EI8.V##RISCV"  :10,   
}

vldst_map = InstructionMap("vldst_instructions", vldst_instructions)

vld_whole_instructions = {
    "VL1RE16.V##RISCV"      :10,  
    "VL1RE32.V##RISCV"      :10,  
    "VL1RE64.V##RISCV"      :10,  
    "VL1RE8.V##RISCV"       :10,  
    "VL2RE16.V##RISCV"      :10,  
    "VL2RE32.V##RISCV"      :10,  
    "VL2RE64.V##RISCV"      :10,  
    "VL2RE8.V##RISCV"       :10,  
    "VL4RE16.V##RISCV"      :10,  
    "VL4RE32.V##RISCV"      :10,  
    "VL4RE64.V##RISCV"      :10,  
    "VL4RE8.V##RISCV"       :10,  
    "VL8RE16.V##RISCV"      :10,  
    "VL8RE32.V##RISCV"      :10,  
    "VL8RE64.V##RISCV"      :10,  
    "VL8RE8.V##RISCV"       :10,  
    }
vld_whole_map = InstructionMap("vld_whole_instructions", vld_whole_instructions)

vld_mask_instructions = {
    "VLM.V##RISCV"          :10,  
    }
vld_mask_map = InstructionMap("vld_mask_instructions", vld_mask_instructions)

vld_unitstride_instructions = {
    "VLE16.V##RISCV"        :10,  
    "VLE32.V##RISCV"        :10,  
    "VLE64.V##RISCV"        :10,  
    "VLE8.V##RISCV"         :10,  
    }
vld_unitstride_map = InstructionMap("vld_unitstride_instructions", vld_unitstride_instructions)

vld_unitstride_fof_instructions = {
    "VLE16FF.V##RISCV"      :10,  
    "VLE32FF.V##RISCV"      :10,  
    "VLE64FF.V##RISCV"      :10,  
    "VLE8FF.V##RISCV"       :10,  
    }
vld_unitstride_fof_map = InstructionMap("vld_unitstride_fof_instructions", vld_unitstride_fof_instructions)

vld_segment_unitstride_instructions = {
    "VLSEG2E16.V##RISCV"    :10,  
    "VLSEG2E16FF.V##RISCV"  :10,  
    "VLSEG2E32.V##RISCV"    :10,  
    "VLSEG2E32FF.V##RISCV"  :10,  
    "VLSEG2E64.V##RISCV"    :10,  
    "VLSEG2E64FF.V##RISCV"  :10,  
    "VLSEG2E8.V##RISCV"     :10,  
    "VLSEG2E8FF.V##RISCV"   :10,  
    "VLSEG3E16.V##RISCV"    :10,  
    "VLSEG3E16FF.V##RISCV"  :10,  
    "VLSEG3E32.V##RISCV"    :10,  
    "VLSEG3E32FF.V##RISCV"  :10,  
    "VLSEG3E64.V##RISCV"    :10,  
    "VLSEG3E64FF.V##RISCV"  :10,  
    "VLSEG3E8.V##RISCV"     :10,  
    "VLSEG3E8FF.V##RISCV"   :10,  
    "VLSEG4E16.V##RISCV"    :10,  
    "VLSEG4E16FF.V##RISCV"  :10,  
    "VLSEG4E32.V##RISCV"    :10,  
    "VLSEG4E32FF.V##RISCV"  :10,  
    "VLSEG4E64.V##RISCV"    :10,  
    "VLSEG4E64FF.V##RISCV"  :10,  
    "VLSEG4E8.V##RISCV"     :10,  
    "VLSEG4E8FF.V##RISCV"   :10,  
    "VLSEG5E16.V##RISCV"    :10,  
    "VLSEG5E16FF.V##RISCV"  :10,  
    "VLSEG5E32.V##RISCV"    :10,  
    "VLSEG5E32FF.V##RISCV"  :10,  
    "VLSEG5E64.V##RISCV"    :10,  
    "VLSEG5E64FF.V##RISCV"  :10,  
    "VLSEG5E8.V##RISCV"     :10,  
    "VLSEG5E8FF.V##RISCV"   :10,  
    "VLSEG6E16.V##RISCV"    :10,  
    "VLSEG6E16FF.V##RISCV"  :10,  
    "VLSEG6E32.V##RISCV"    :10,  
    "VLSEG6E32FF.V##RISCV"  :10,  
    "VLSEG6E64.V##RISCV"    :10,  
    "VLSEG6E64FF.V##RISCV"  :10,  
    "VLSEG6E8.V##RISCV"     :10,  
    "VLSEG6E8FF.V##RISCV"   :10,  
    "VLSEG7E16.V##RISCV"    :10,  
    "VLSEG7E16FF.V##RISCV"  :10,  
    "VLSEG7E32.V##RISCV"    :10,  
    "VLSEG7E32FF.V##RISCV"  :10,  
    "VLSEG7E64.V##RISCV"    :10,  
    "VLSEG7E64FF.V##RISCV"  :10,  
    "VLSEG7E8.V##RISCV"     :10,  
    "VLSEG7E8FF.V##RISCV"   :10,  
    "VLSEG8E16.V##RISCV"    :10,  
    "VLSEG8E16FF.V##RISCV"  :10,  
    "VLSEG8E32.V##RISCV"    :10,  
    "VLSEG8E32FF.V##RISCV"  :10,  
    "VLSEG8E64.V##RISCV"    :10,  
    "VLSEG8E64FF.V##RISCV"  :10,  
    "VLSEG8E8.V##RISCV"     :10,  
    "VLSEG8E8FF.V##RISCV"   :10,  
    }
vld_segment_unitstride_map = InstructionMap("vld_segment_unitstride_instructions", vld_segment_unitstride_instructions)

vld_strided_instructions = {
    "VLSE16.V##RISCV"       :10,  
    "VLSE32.V##RISCV"       :10,  
    "VLSE64.V##RISCV"       :10,  
    "VLSE8.V##RISCV"        :10,  
    }
vld_strided_map = InstructionMap("vld_strided_instructions", vld_strided_instructions)

vld_segment_strided_instructions = {
    "VLSSEG2E16.V##RISCV"   :10,  
    "VLSSEG2E32.V##RISCV"   :10,  
    "VLSSEG2E64.V##RISCV"   :10,  
    "VLSSEG2E8.V##RISCV"    :10,  
    "VLSSEG3E16.V##RISCV"   :10,  
    "VLSSEG3E32.V##RISCV"   :10,  
    "VLSSEG3E64.V##RISCV"   :10,  
    "VLSSEG3E8.V##RISCV"    :10,  
    "VLSSEG4E16.V##RISCV"   :10,  
    "VLSSEG4E32.V##RISCV"   :10,  
    "VLSSEG4E64.V##RISCV"   :10,  
    "VLSSEG4E8.V##RISCV"    :10,  
    "VLSSEG5E16.V##RISCV"   :10,  
    "VLSSEG5E32.V##RISCV"   :10,  
    "VLSSEG5E64.V##RISCV"   :10,  
    "VLSSEG5E8.V##RISCV"    :10,  
    "VLSSEG6E16.V##RISCV"   :10,  
    "VLSSEG6E32.V##RISCV"   :10,  
    "VLSSEG6E64.V##RISCV"   :10,  
    "VLSSEG6E8.V##RISCV"    :10,  
    "VLSSEG7E16.V##RISCV"   :10,  
    "VLSSEG7E32.V##RISCV"   :10,  
    "VLSSEG7E64.V##RISCV"   :10,  
    "VLSSEG7E8.V##RISCV"    :10,  
    "VLSSEG8E16.V##RISCV"   :10,  
    "VLSSEG8E32.V##RISCV"   :10,  
    "VLSSEG8E64.V##RISCV"   :10,  
    "VLSSEG8E8.V##RISCV"    :10,  
    }
vld_segment_strided_map = InstructionMap("vld_segment_strided_instructions", vld_segment_strided_instructions)

vld_index_ordered_instructions = {
    "VLOXEI16.V##RISCV"     :10,  
    "VLOXEI32.V##RISCV"     :10,  
    "VLOXEI64.V##RISCV"     :10,  
    "VLOXEI8.V##RISCV"      :10,  
    }
vld_index_ordered_map = InstructionMap("vld_index_ordered_instructions", vld_index_ordered_instructions)

vld_segment_index_ordered_instructions = {
    "VLOXSEG2EI16.V##RISCV" :10,  
    "VLOXSEG2EI32.V##RISCV" :10,  
    "VLOXSEG2EI64.V##RISCV" :10,  
    "VLOXSEG2EI8.V##RISCV"  :10,  
    "VLOXSEG3EI16.V##RISCV" :10,  
    "VLOXSEG3EI32.V##RISCV" :10,  
    "VLOXSEG3EI64.V##RISCV" :10,  
    "VLOXSEG3EI8.V##RISCV"  :10,  
    "VLOXSEG4EI16.V##RISCV" :10,  
    "VLOXSEG4EI32.V##RISCV" :10,  
    "VLOXSEG4EI64.V##RISCV" :10,  
    "VLOXSEG4EI8.V##RISCV"  :10,  
    "VLOXSEG5EI16.V##RISCV" :10,  
    "VLOXSEG5EI32.V##RISCV" :10,  
    "VLOXSEG5EI64.V##RISCV" :10,  
    "VLOXSEG5EI8.V##RISCV"  :10,  
    "VLOXSEG6EI16.V##RISCV" :10,  
    "VLOXSEG6EI32.V##RISCV" :10,  
    "VLOXSEG6EI64.V##RISCV" :10,  
    "VLOXSEG6EI8.V##RISCV"  :10,  
    "VLOXSEG7EI16.V##RISCV" :10,  
    "VLOXSEG7EI32.V##RISCV" :10,  
    "VLOXSEG7EI64.V##RISCV" :10,  
    "VLOXSEG7EI8.V##RISCV"  :10,  
    "VLOXSEG8EI16.V##RISCV" :10,  
    "VLOXSEG8EI32.V##RISCV" :10,  
    "VLOXSEG8EI64.V##RISCV" :10,  
    "VLOXSEG8EI8.V##RISCV"  :10,  
    }
vld_segment_index_ordered_map = InstructionMap("vld_segment_index_ordered_instructions", vld_segment_index_ordered_instructions)

vld_index_unordered_instructions = {
    "VLUXEI16.V##RISCV"     :10,  
    "VLUXEI32.V##RISCV"     :10,  
    "VLUXEI64.V##RISCV"     :10,  
    "VLUXEI8.V##RISCV"      :10,  
    }
vld_index_unordered_map = InstructionMap("vld_index_unordered_instructions", vld_index_unordered_instructions)

vld_segment_index_unordered_instructions = {
    "VLUXSEG2EI16.V##RISCV" :10,  
    "VLUXSEG2EI32.V##RISCV" :10,  
    "VLUXSEG2EI64.V##RISCV" :10,  
    "VLUXSEG2EI8.V##RISCV"  :10,  
    "VLUXSEG3EI16.V##RISCV" :10,  
    "VLUXSEG3EI32.V##RISCV" :10,  
    "VLUXSEG3EI64.V##RISCV" :10,  
    "VLUXSEG3EI8.V##RISCV"  :10,  
    "VLUXSEG4EI16.V##RISCV" :10,  
    "VLUXSEG4EI32.V##RISCV" :10,  
    "VLUXSEG4EI64.V##RISCV" :10,  
    "VLUXSEG4EI8.V##RISCV"  :10,  
    "VLUXSEG5EI16.V##RISCV" :10,  
    "VLUXSEG5EI32.V##RISCV" :10,  
    "VLUXSEG5EI64.V##RISCV" :10,  
    "VLUXSEG5EI8.V##RISCV"  :10,  
    "VLUXSEG6EI16.V##RISCV" :10,  
    "VLUXSEG6EI32.V##RISCV" :10,  
    "VLUXSEG6EI64.V##RISCV" :10,  
    "VLUXSEG6EI8.V##RISCV"  :10,  
    "VLUXSEG7EI16.V##RISCV" :10,  
    "VLUXSEG7EI32.V##RISCV" :10,  
    "VLUXSEG7EI64.V##RISCV" :10,  
    "VLUXSEG7EI8.V##RISCV"  :10,  
    "VLUXSEG8EI16.V##RISCV" :10,  
    "VLUXSEG8EI32.V##RISCV" :10,  
    "VLUXSEG8EI64.V##RISCV" :10,  
    "VLUXSEG8EI8.V##RISCV"  :10,  
    }
vld_segment_index_unordered_map = InstructionMap("vld_segment_index_unordered_instructions", vld_segment_index_unordered_instructions)

vst_whole_instructions = {
    "VS1R.V##RISCV"         :10,  
    "VS2R.V##RISCV"         :10,  
    "VS4R.V##RISCV"         :10,  
    "VS8R.V##RISCV"         :10,  
    }
vst_whole_map = InstructionMap("vst_whole_instructions", vst_whole_instructions)

vst_mask_instructions = {
    "VSM.V##RISCV"          :10,  
    }
vst_mask_map = InstructionMap("vst_mask_instructions", vst_mask_instructions)

vst_unitstride_instructions = {
    "VSE16.V##RISCV"        :10,  
    "VSE32.V##RISCV"        :10,  
    "VSE64.V##RISCV"        :10,  
    "VSE8.V##RISCV"         :10,  
    }
vst_unitstride_map = InstructionMap("vst_unitstride_instructions", vst_unitstride_instructions)

vst_segment_unitstride_instructions = {
    "VSSEG2E16.V##RISCV"    :10,  
    "VSSEG2E32.V##RISCV"    :10,  
    "VSSEG2E64.V##RISCV"    :10,  
    "VSSEG2E8.V##RISCV"     :10,  
    "VSSEG3E16.V##RISCV"    :10,  
    "VSSEG3E32.V##RISCV"    :10,  
    "VSSEG3E64.V##RISCV"    :10,  
    "VSSEG3E8.V##RISCV"     :10,  
    "VSSEG4E16.V##RISCV"    :10,  
    "VSSEG4E32.V##RISCV"    :10,  
    "VSSEG4E64.V##RISCV"    :10,  
    "VSSEG4E8.V##RISCV"     :10,  
    "VSSEG5E16.V##RISCV"    :10,  
    "VSSEG5E32.V##RISCV"    :10,  
    "VSSEG5E64.V##RISCV"    :10,  
    "VSSEG5E8.V##RISCV"     :10,  
    "VSSEG6E16.V##RISCV"    :10,  
    "VSSEG6E32.V##RISCV"    :10,  
    "VSSEG6E64.V##RISCV"    :10,  
    "VSSEG6E8.V##RISCV"     :10,  
    "VSSEG7E16.V##RISCV"    :10,  
    "VSSEG7E32.V##RISCV"    :10,  
    "VSSEG7E64.V##RISCV"    :10,  
    "VSSEG7E8.V##RISCV"     :10,  
    "VSSEG8E16.V##RISCV"    :10,  
    "VSSEG8E32.V##RISCV"    :10,  
    "VSSEG8E64.V##RISCV"    :10,  
    "VSSEG8E8.V##RISCV"     :10,  
    }
vst_segment_unitstride_map = InstructionMap("vst_segment_unitstride_instructions", vst_segment_unitstride_instructions)

vst_strided_instructions = {
    "VSSE16.V##RISCV"       :10,  
    "VSSE32.V##RISCV"       :10,  
    "VSSE64.V##RISCV"       :10,  
    "VSSE8.V##RISCV"        :10,  
    }
vst_strided_map = InstructionMap("vst_strided_instructions", vst_strided_instructions)

vst_segment_strided_instructions = {
    "VSSSEG2E16.V##RISCV"   :10,  
    "VSSSEG2E32.V##RISCV"   :10,  
    "VSSSEG2E64.V##RISCV"   :10,  
    "VSSSEG2E8.V##RISCV"    :10,  
    "VSSSEG3E16.V##RISCV"   :10,  
    "VSSSEG3E32.V##RISCV"   :10,  
    "VSSSEG3E64.V##RISCV"   :10,  
    "VSSSEG3E8.V##RISCV"    :10,  
    "VSSSEG4E16.V##RISCV"   :10,  
    "VSSSEG4E32.V##RISCV"   :10,  
    "VSSSEG4E64.V##RISCV"   :10,  
    "VSSSEG4E8.V##RISCV"    :10,  
    "VSSSEG5E16.V##RISCV"   :10,  
    "VSSSEG5E32.V##RISCV"   :10,  
    "VSSSEG5E64.V##RISCV"   :10,  
    "VSSSEG5E8.V##RISCV"    :10,  
    "VSSSEG6E16.V##RISCV"   :10,  
    "VSSSEG6E32.V##RISCV"   :10,  
    "VSSSEG6E64.V##RISCV"   :10,  
    "VSSSEG6E8.V##RISCV"    :10,  
    "VSSSEG7E16.V##RISCV"   :10,  
    "VSSSEG7E32.V##RISCV"   :10,  
    "VSSSEG7E64.V##RISCV"   :10,  
    "VSSSEG7E8.V##RISCV"    :10,  
    "VSSSEG8E16.V##RISCV"   :10,  
    "VSSSEG8E32.V##RISCV"   :10,  
    "VSSSEG8E64.V##RISCV"   :10,  
    "VSSSEG8E8.V##RISCV"    :10,  
    }
vst_segment_strided_map = InstructionMap("vst_segment_strided_instructions", vst_segment_strided_instructions)

vst_index_ordered_instructions = {
    "VSOXEI16.V##RISCV"     :10,  
    "VSOXEI32.V##RISCV"     :10,  
    "VSOXEI64.V##RISCV"     :10,  
    "VSOXEI8.V##RISCV"      :10,  
    }
vst_index_ordered_map = InstructionMap("vst_index_ordered_instructions", vst_index_ordered_instructions)

vst_segment_index_ordered_instructions = {
    "VSOXSEG2EI16.V##RISCV" :10,  
    "VSOXSEG2EI32.V##RISCV" :10,  
    "VSOXSEG2EI64.V##RISCV" :10,  
    "VSOXSEG2EI8.V##RISCV"  :10,  
    "VSOXSEG3EI16.V##RISCV" :10,  
    "VSOXSEG3EI32.V##RISCV" :10,  
    "VSOXSEG3EI64.V##RISCV" :10,  
    "VSOXSEG3EI8.V##RISCV"  :10,  
    "VSOXSEG4EI16.V##RISCV" :10,  
    "VSOXSEG4EI32.V##RISCV" :10,  
    "VSOXSEG4EI64.V##RISCV" :10,  
    "VSOXSEG4EI8.V##RISCV"  :10,  
    "VSOXSEG5EI16.V##RISCV" :10,  
    "VSOXSEG5EI32.V##RISCV" :10,  
    "VSOXSEG5EI64.V##RISCV" :10,  
    "VSOXSEG5EI8.V##RISCV"  :10,  
    "VSOXSEG6EI16.V##RISCV" :10,  
    "VSOXSEG6EI32.V##RISCV" :10,  
    "VSOXSEG6EI64.V##RISCV" :10,  
    "VSOXSEG6EI8.V##RISCV"  :10,  
    "VSOXSEG7EI16.V##RISCV" :10,  
    "VSOXSEG7EI32.V##RISCV" :10,  
    "VSOXSEG7EI64.V##RISCV" :10,  
    "VSOXSEG7EI8.V##RISCV"  :10,  
    "VSOXSEG8EI16.V##RISCV" :10,  
    "VSOXSEG8EI32.V##RISCV" :10,  
    "VSOXSEG8EI64.V##RISCV" :10,  
    "VSOXSEG8EI8.V##RISCV"  :10,  
    }
vst_segment_index_ordered_map = InstructionMap("vst_segment_index_ordered_instructions", vst_segment_index_ordered_instructions)

vst_index_unordered_instructions = {
    "VSUXEI16.V##RISCV"     :10,  
    "VSUXEI32.V##RISCV"     :10,  
    "VSUXEI64.V##RISCV"     :10,  
    "VSUXEI8.V##RISCV"      :10,  
    }
vst_segment_index_ordered_map = InstructionMap("vst_index_unordered_instructions", vst_index_unordered_instructions)

vst_segment_index_unordered_instructions = {
    "VSUXSEG2EI16.V##RISCV" :10,  
    "VSUXSEG2EI32.V##RISCV" :10,  
    "VSUXSEG2EI64.V##RISCV" :10,  
    "VSUXSEG2EI8.V##RISCV"  :10,  
    "VSUXSEG3EI16.V##RISCV" :10,  
    "VSUXSEG3EI32.V##RISCV" :10,  
    "VSUXSEG3EI64.V##RISCV" :10,  
    "VSUXSEG3EI8.V##RISCV"  :10,  
    "VSUXSEG4EI16.V##RISCV" :10,  
    "VSUXSEG4EI32.V##RISCV" :10,  
    "VSUXSEG4EI64.V##RISCV" :10,  
    "VSUXSEG4EI8.V##RISCV"  :10,  
    "VSUXSEG5EI16.V##RISCV" :10,  
    "VSUXSEG5EI32.V##RISCV" :10,  
    "VSUXSEG5EI64.V##RISCV" :10,  
    "VSUXSEG5EI8.V##RISCV"  :10,  
    "VSUXSEG6EI16.V##RISCV" :10,  
    "VSUXSEG6EI32.V##RISCV" :10,  
    "VSUXSEG6EI64.V##RISCV" :10,  
    "VSUXSEG6EI8.V##RISCV"  :10,  
    "VSUXSEG7EI16.V##RISCV" :10,  
    "VSUXSEG7EI32.V##RISCV" :10,  
    "VSUXSEG7EI64.V##RISCV" :10,  
    "VSUXSEG7EI8.V##RISCV"  :10,  
    "VSUXSEG8EI16.V##RISCV" :10,  
    "VSUXSEG8EI32.V##RISCV" :10,  
    "VSUXSEG8EI64.V##RISCV" :10,  
    "VSUXSEG8EI8.V##RISCV"  :10,   
}
vst_segment_index_unordered_map = InstructionMap("vst_segment_index_unordered_instructions", vst_segment_index_unordered_instructions)

vldst_supported_instructions = merge(
        vld_whole_instructions,
        vld_mask_instructions,
        vld_unitstride_instructions,
        vld_segment_unitstride_instructions,
        #vld_unitstride_fof_instructions,
        vld_strided_instructions,
        vld_segment_strided_instructions,
        vld_index_ordered_instructions,
        vld_segment_index_ordered_instructions,
        vld_index_unordered_instructions,
        vld_segment_index_unordered_instructions,
        vst_whole_instructions,
        vst_mask_instructions,
        vst_unitstride_instructions,
        vst_segment_unitstride_instructions,
        vst_strided_instructions,
        vst_segment_strided_instructions,
        vst_index_ordered_instructions,
        vst_segment_index_ordered_instructions,
        vst_index_unordered_instructions,
        vst_segment_index_unordered_instructions,
)
vld_supported_instructions = merge(
        vld_whole_instructions,
        vld_mask_instructions,
        vld_unitstride_instructions,
        vld_segment_unitstride_instructions,
        #vld_unitstride_fof_instructions,
        vld_strided_instructions,
        vld_segment_strided_instructions,
        vld_index_ordered_instructions,
        vld_segment_index_ordered_instructions,
        vld_index_unordered_instructions,
        vld_segment_index_unordered_instructions,
)
vldst_supported_map = InstructionMap("vldst_supported_instructions", vldst_supported_instructions)
vld_supported_map = InstructionMap("vld_supported_instructions", vld_supported_instructions)
vldst_map = InstructionMap("vldst_instructions", vldst_instructions)

# v-integer has 139 insts in total under V-SPEC V1.0
vinteger_instructions = {
    "VADD.VI##RISCV": 10,
    "VADD.VV##RISCV": 10,
    "VADD.VX##RISCV": 10,
    "VSUB.VV##RISCV": 10,
    "VSUB.VX##RISCV": 10,
    "VRSUB.VI##RISCV": 10,
    "VRSUB.VX##RISCV": 10,
    "VWADDU.VV##RISCV": 10,
    "VWADDU.VX##RISCV": 10,
    "VWSUBU.VV##RISCV": 10,
    "VWSUBU.VX##RISCV": 10,
    "VWADD.VV##RISCV": 10,
    "VWADD.VX##RISCV": 10,
    "VWSUB.VV##RISCV": 10,
    "VWSUB.VX##RISCV": 10,
    "VWADDU.WV##RISCV": 10,  
    "VWADDU.WX##RISCV": 10,
    "VWSUBU.WV##RISCV": 10,  
    "VWSUBU.WX##RISCV": 10,     
    "VWADD.WV##RISCV": 10,  
    "VWADD.WX##RISCV": 10,  
    "VWSUB.WV##RISCV": 10,  
    "VWSUB.WX##RISCV": 10,  
    "VZEXT.VF2##RISCV": 10,
    "VSEXT.VF2##RISCV": 10,    
    "VZEXT.VF4##RISCV": 10,
    "VSEXT.VF4##RISCV": 10,     
    "VZEXT.VF8##RISCV": 10,
    "VSEXT.VF8##RISCV": 10,
    "VADC.VIM##RISCV": 10,  
    "VADC.VVM##RISCV": 10,   
    "VADC.VXM##RISCV": 10,
    "VMADC.VIM##RISCV": 10,
    "VMADC.VVM##RISCV": 10,
    "VMADC.VXM##RISCV": 10,
    "VMADC.VI##RISCV": 10,
    "VMADC.VV##RISCV": 10,
    "VMADC.VX##RISCV": 10,
    "VSBC.VVM##RISCV": 10,   
    "VSBC.VXM##RISCV": 10,
    "VMSBC.VVM##RISCV": 10,
    "VMSBC.VXM##RISCV": 10,
    "VMSBC.VV##RISCV": 10,
    "VMSBC.VX##RISCV": 10,
    "VAND.VI##RISCV": 10,
    "VAND.VV##RISCV": 10,
    "VAND.VX##RISCV": 10,
    "VOR.VI##RISCV": 10,
    "VOR.VV##RISCV": 10,
    "VOR.VX##RISCV": 10,
    "VXOR.VI##RISCV": 10,
    "VXOR.VV##RISCV": 10,
    "VXOR.VX##RISCV": 10,
    "VSLL.VI##RISCV": 10,
    "VSLL.VV##RISCV": 10,
    "VSLL.VX##RISCV": 10,
    "VSRL.VI##RISCV": 10,
    "VSRL.VV##RISCV": 10,
    "VSRL.VX##RISCV": 10,    
    "VSRA.VI##RISCV": 10,
    "VSRA.VV##RISCV": 10,
    "VSRA.VX##RISCV": 10,
    "VNSRL.WI##RISCV": 10,
    "VNSRL.WV##RISCV": 10,
    "VNSRL.WX##RISCV": 10,    
    "VNSRA.WI##RISCV": 10,
    "VNSRA.WV##RISCV": 10,
    "VNSRA.WX##RISCV": 10,
    "VMSEQ.VI##RISCV": 10,
    "VMSEQ.VV##RISCV": 10,
    "VMSEQ.VX##RISCV": 10,
    "VMSNE.VI##RISCV": 10,
    "VMSNE.VV##RISCV": 10,
    "VMSNE.VX##RISCV": 10,
    "VMSLTU.VV##RISCV": 10,
    "VMSLTU.VX##RISCV": 10, 
    "VMSLT.VV##RISCV": 10,
    "VMSLT.VX##RISCV": 10,
    "VMSLEU.VI##RISCV": 10,
    "VMSLEU.VV##RISCV": 10,
    "VMSLEU.VX##RISCV": 10, 
    "VMSLE.VI##RISCV": 10,
    "VMSLE.VV##RISCV": 10,
    "VMSLE.VX##RISCV": 10,
    "VMSGTU.VI##RISCV": 10,
    "VMSGTU.VX##RISCV": 10,    
    "VMSGT.VI##RISCV": 10,
    "VMSGT.VX##RISCV": 10,
    "VMINU.VV##RISCV": 10,
    "VMINU.VX##RISCV": 10,
    "VMIN.VV##RISCV": 10,
    "VMIN.VX##RISCV": 10,
    "VMAXU.VV##RISCV": 10,
    "VMAXU.VX##RISCV": 10,    
    "VMAX.VV##RISCV": 10,
    "VMAX.VX##RISCV": 10,
    "VMUL.VV##RISCV": 10,
    "VMUL.VX##RISCV": 10,
    "VMULH.VV##RISCV": 10,
    "VMULH.VX##RISCV": 10,
    "VMULHU.VV##RISCV": 10,
    "VMULHU.VX##RISCV": 10,    
    "VMULHSU.VV##RISCV": 10,
    "VMULHSU.VX##RISCV": 10,
    "VDIVU.VV##RISCV": 10,
    "VDIVU.VX##RISCV": 10,
    "VDIV.VV##RISCV": 10,
    "VDIV.VX##RISCV": 10,
    "VREMU.VV##RISCV": 10,
    "VREMU.VX##RISCV": 10,
    "VREM.VV##RISCV": 10,
    "VREM.VX##RISCV": 10,
    "VWMUL.VV##RISCV": 10,
    "VWMUL.VX##RISCV": 10,
    "VWMULU.VV##RISCV": 10,
    "VWMULU.VX##RISCV": 10,    
    "VWMULSU.VV##RISCV": 10,
    "VWMULSU.VX##RISCV": 10,
    "VMACC.VV##RISCV": 10,
    "VMACC.VX##RISCV": 10,
    "VNMSAC.VV##RISCV": 10,
    "VNMSAC.VX##RISCV": 10,    
    "VMADD.VV##RISCV": 10,
    "VMADD.VX##RISCV": 10,
    "VNMSUB.VV##RISCV": 10,
    "VNMSUB.VX##RISCV": 10,
    "VWMACCU.VV##RISCV": 10,
    "VWMACCU.VX##RISCV": 10,
    "VWMACC.VV##RISCV": 10,
    "VWMACC.VX##RISCV": 10,
    "VWMACCSU.VV##RISCV": 10,
    "VWMACCSU.VX##RISCV": 10,
    "VWMACCUS.VX##RISCV": 10,
    "VMERGE.VIM##RISCV": 10,  
    "VMERGE.VVM##RISCV": 10, 
    "VMERGE.VXM##RISCV": 10,  
    "VMV.V.V##RISCV": 10,
    "VMV.V.X##RISCV": 10,
    "VMV.V.V##RISCV": 10,    
}

vinteger_map = InstructionMap("vinteger_instructions", vinteger_instructions)

# v-fixed point has 32 insts in total under V-SPEC V1.0
vfixed_point_instructions = {
    "VSADDU.VI##RISCV": 10,
    "VSADDU.VV##RISCV": 10,
    "VSADDU.VX##RISCV": 10,
    "VSADD.VI##RISCV": 10,
    "VSADD.VV##RISCV": 10,
    "VSADD.VX##RISCV": 10,
    "VSSUBU.VV##RISCV": 10,
    "VSSUBU.VX##RISCV": 10,    
    "VSSUB.VV##RISCV": 10,
    "VSSUB.VX##RISCV": 10,
    "VAADDU.VV##RISCV": 10,
    "VAADDU.VX##RISCV": 10,    
    "VAADD.VV##RISCV": 10,
    "VAADD.VX##RISCV": 10,
    "VASUBU.VV##RISCV": 10,
    "VASUBU.VX##RISCV": 10,    
    "VASUB.VV##RISCV": 10,
    "VASUB.VX##RISCV": 10,
    "VSMUL.VV##RISCV": 10,
    "VSMUL.VX##RISCV": 10,
    "VSSRL.VI##RISCV": 10,
    "VSSRL.VV##RISCV": 10,
    "VSSRL.VX##RISCV": 10,    
    "VSSRA.VI##RISCV": 10,
    "VSSRA.VV##RISCV": 10,
    "VSSRA.VX##RISCV": 10,
    "VNCLIPU.WI##RISCV": 10,  
    "VNCLIPU.WV##RISCV": 10, 
    "VNCLIPU.WX##RISCV": 10,    
    "VNCLIP.WI##RISCV": 10, 
    "VNCLIP.WV##RISCV": 10, 
    "VNCLIP.WX##RISCV": 10, 
}

vfixed_point_map = InstructionMap("vfixed_point_instructions", vfixed_point_instructions)

# v-float point has 91 insts in total under V-SPEC V1.0
vfloating_point_instructions = {
    "VFADD.VF##RISCV": 10,
    "VFADD.VV##RISCV": 10,
    "VFSUB.VF##RISCV": 10,
    "VFSUB.VV##RISCV": 10,
    "VFRSUB.VF##RISCV": 10,
    "VFWADD.VF##RISCV": 10,
    "VFWADD.VV##RISCV": 10,
    "VFWSUB.VF##RISCV": 10,
    "VFWSUB.VV##RISCV": 10,    
    "VFWADD.WF##RISCV": 10,  
    "VFWADD.WV##RISCV": 10,  
    "VFWSUB.WF##RISCV": 10, 
    "VFWSUB.WV##RISCV": 10,  
    "VFMUL.VF##RISCV": 10,
    "VFMUL.VV##RISCV": 10,
    "VFDIV.VF##RISCV": 10,
    "VFDIV.VV##RISCV": 10,
    "VFRDIV.VF##RISCV": 10,
    "VFWMUL.VF##RISCV": 10,
    "VFWMUL.VV##RISCV": 10,
    "VFMACC.VF##RISCV": 10,
    "VFMACC.VV##RISCV": 10,
    "VFNMACC.VF##RISCV": 10,
    "VFNMACC.VV##RISCV": 10,
    "VFMSAC.VF##RISCV": 10,
    "VFMSAC.VV##RISCV": 10,    
    "VFNMSAC.VF##RISCV": 10,
    "VFNMSAC.VV##RISCV": 10, 
    "VFMADD.VF##RISCV": 10,
    "VFMADD.VV##RISCV": 10,
    "VFNMADD.VF##RISCV": 10,
    "VFNMADD.VV##RISCV": 10,
    "VFMSUB.VF##RISCV": 10,
    "VFMSUB.VV##RISCV": 10,
    "VFNMSUB.VF##RISCV": 10,
    "VFNMSUB.VV##RISCV": 10,
    "VFWMACC.VF##RISCV": 10,
    "VFWMACC.VV##RISCV": 10,
    "VFWNMACC.VF##RISCV": 10,
    "VFWNMACC.VV##RISCV": 10,
    "VFWMSAC.VF##RISCV": 10,
    "VFWMSAC.VV##RISCV": 10,    
    "VFWNMSAC.VF##RISCV": 10,
    "VFWNMSAC.VV##RISCV": 10,
    "VFSQRT.V##RISCV": 10,
    "VFRSQRT7.V##RISCV":10,
    "VFREC7.V##RISCV":10,
    "VFMIN.VF##RISCV": 10,
    "VFMIN.VV##RISCV": 10,    
    "VFMAX.VF##RISCV": 10,
    "VFMAX.VV##RISCV": 10,
    "VFSGNJ.VF##RISCV": 10,
    "VFSGNJ.VV##RISCV": 10,
    "VFSGNJN.VF##RISCV": 10,
    "VFSGNJN.VV##RISCV": 10,
    "VFSGNJX.VF##RISCV": 10,
    "VFSGNJX.VV##RISCV": 10,
    "VMFEQ.VF##RISCV": 10,
    "VMFEQ.VV##RISCV": 10,
    "VMFNE.VF##RISCV": 10,
    "VMFNE.VV##RISCV": 10, 
    "VMFLT.VF##RISCV": 10,
    "VMFLT.VV##RISCV": 10,
    "VMFLE.VF##RISCV": 10,
    "VMFLE.VV##RISCV": 10,    
    "VMFGE.VF##RISCV": 10,
    "VMFGT.VF##RISCV": 10,
    "VFCLASS.V##RISCV": 10,
    "VFMERGE.VFM##RISCV":10,
    "VFMV.V.F##RISCV":10,
    "VFCVT.XU.F.V##RISCV": 10,
    "VFCVT.X.F.V##RISCV": 10,    
    "VFCVT.RTZ.XU.F.V##RISCV" :10,
    "VFCVT.RTZ.X.F.V##RISCV"  :10,
    "VFCVT.F.XU.V##RISCV": 10,
    "VFCVT.F.X.V##RISCV": 10,
    "VFWCVT.XU.F.V##RISCV": 10,
    "VFWCVT.X.F.V##RISCV": 10,    
    "VFWCVT.RTZ.XU.F.V##RISCV":10,
    "VFWCVT.RTZ.X.F.V##RISCV" :10,
    "VFWCVT.F.XU.V##RISCV": 10,    
    "VFWCVT.F.X.V##RISCV": 10,
    "VFWCVT.F.F.V##RISCV": 10, 
    "VFNCVT.XU.F.W##RISCV": 10,
    "VFNCVT.X.F.W##RISCV": 10,    
    "VFNCVT.RTZ.XU.F.W##RISCV":10,
    "VFNCVT.RTZ.X.F.W##RISCV" :10,
    "VFNCVT.F.XU.W##RISCV": 10,    
    "VFNCVT.F.X.W##RISCV": 10,
    "VFNCVT.F.F.W##RISCV": 10,    
    "VFNCVT.ROD.F.F.W##RISCV": 10,
}

vfloating_point_map = InstructionMap("vfloating_point_instructions", vfloating_point_instructions)

# v-reduction has 16 insts in total under V-SPEC V1.0
vreduction_instructions = {
    "VREDSUM.VS##RISCV": 10,  
    "VREDMAXU.VS##RISCV": 10,   
    "VREDMAX.VS##RISCV": 10,  
    "VREDMINU.VS##RISCV": 10,  
    "VREDMIN.VS##RISCV": 10,  
    "VREDAND.VS##RISCV": 10,  
    "VREDOR.VS##RISCV": 10,  
    "VREDXOR.VS##RISCV": 10,    
    "VWREDSUMU.VS##RISCV": 10,  
    "VWREDSUM.VS##RISCV": 10, 
    "VFREDOSUM.VS##RISCV": 10, 
    "VFREDUSUM.VS##RISCV": 10,   
    "VFREDMAX.VS##RISCV": 10, 
    "VFREDMIN.VS##RISCV": 10,
    "VFWREDOSUM.VS##RISCV": 10, 
    "VFWREDUSUM.VS##RISCV": 10, 
}

vreduction_map = InstructionMap("vreduction_instructions", vreduction_instructions)

# v-mask has 15 insts in total under V-SPEC V1.0
vmask_instructions = {
    "VMAND.MM##RISCV": 10,   
    "VMNAND.MM##RISCV": 10,  
    "VMANDN.MM##RISCV": 10,  
    "VMXOR.MM##RISCV": 10,    
    "VMOR.MM##RISCV": 10,        
    "VMNOR.MM##RISCV": 10,   
    "VMORN.MM##RISCV": 10,   
    "VMXNOR.MM##RISCV": 10,  
    "VCPOP.M##RISCV": 10,    
    "VFIRST.M##RISCV": 10,   
    "VMSBF.M##RISCV": 10,    
    "VMSIF.M##RISCV": 10,    
    "VMSOF.M##RISCV": 10,    
    "VIOTA.M##RISCV": 10,    
    "VID.V##RISCV": 10,        
}

vmask_map = InstructionMap("vmask_instructions", vmask_instructions)

# v-permute has 21 insts in total under V-SPEC V1.0
vpermutation_instructions = {
    "VMV.S.X##RISCV": 10,
    "VMV.X.S##RISCV": 10,
    "VFMV.F.S##RISCV": 10,
    "VFMV.S.F##RISCV": 10,
    "VSLIDEUP.VI##RISCV": 10,
    "VSLIDEUP.VX##RISCV": 10,
    "VSLIDEDOWN.VX##RISCV": 10,     
    "VSLIDEDOWN.VI##RISCV": 10,  
    "VSLIDE1UP.VX##RISCV": 10,  
    "VFSLIDE1UP.VF##RISCV": 10,      
    "VSLIDE1DOWN.VX##RISCV": 10,
    "VFSLIDE1DOWN.VF##RISCV": 10,
    "VRGATHER.VI##RISCV": 10,
    "VRGATHEREI16.VV##RISCV": 10,
    "VRGATHER.VV##RISCV": 10,
    "VRGATHER.VX##RISCV": 10,
    "VCOMPRESS.VM##RISCV": 10,
    "VMV1R.V##RISCV":10,
    "VMV2R.V##RISCV":10,
    "VMV4R.V##RISCV":10,
    "VMV8R.V##RISCV":10,
}

vpermutation_map = ("vpermutation_instructions", vpermutation_instructions)

# v-basic bit-manipulation has 16 insts in total
vbasic_BitManipulation_instructions = {
    "VANDN.VV##RISCV":10,
    "VANDN.VX##RISCV":10,
    "VBREV.V##RISCV":10,
    "VBREV8.V##RISCV":10,
    "VREV8.V##RISCV":10,
    "VCLZ.V##RISCV":10,
    "VCTZ.V##RISCV":10,
    "VCPOP.V##RISCV":10,
    "VROL.VV##RISCV":10,
    "VROL.VX##RISCV":10,
    "VROR.VV##RISCV":10, 
    "VROR.VX##RISCV":10,
    "VROR.VI##RISCV":10, 
    "VWSLL.VV##RISCV":10, 
    "VWSLL.VX##RISCV":10,
    "VWSLL.VI##RISCV":10,     
}

vbasic_BitManipulation_map = InstructionMap("vbasic_BitManipulation_instructions", vbasic_BitManipulation_instructions)

Zvediv_instructions = {
    "VDOT.VV##RISCV": 10,
    "VDOTU.VV##RISCV": 10,
    "VFDOT.VV##RISCV": 10,
}

Zvediv_map = InstructionMap("Zvediv_instructions", Zvediv_instructions)

v_Ld_instructions = {
    "VL1RE16.V##RISCV"      :10,  
    "VL1RE32.V##RISCV"      :10,  
    "VL1RE64.V##RISCV"      :10,  
    "VL1RE8.V##RISCV"       :10,  
    "VL2RE16.V##RISCV"      :10,  
    "VL2RE32.V##RISCV"      :10,  
    "VL2RE64.V##RISCV"      :10,  
    "VL2RE8.V##RISCV"       :10,  
    "VL4RE16.V##RISCV"      :10,  
    "VL4RE32.V##RISCV"      :10,  
    "VL4RE64.V##RISCV"      :10,  
    "VL4RE8.V##RISCV"       :10,  
    "VL8RE16.V##RISCV"      :10,  
    "VL8RE32.V##RISCV"      :10,  
    "VL8RE64.V##RISCV"      :10,  
    "VL8RE8.V##RISCV"       :10,  
    "VLE16.V##RISCV"        :10,  
    "VLE16FF.V##RISCV"      :10,  
    "VLE32.V##RISCV"        :10,  
    "VLE32FF.V##RISCV"      :10,  
    "VLE64.V##RISCV"        :10,  
    "VLE64FF.V##RISCV"      :10,  
    "VLE8.V##RISCV"         :10,  
    "VLE8FF.V##RISCV"       :10,  
    "VLM.V##RISCV"          :10,  
    "VLOXEI16.V##RISCV"     :10,  
    "VLOXEI32.V##RISCV"     :10,  
    "VLOXEI64.V##RISCV"     :10,  
    "VLOXEI8.V##RISCV"      :10,  
    "VLOXSEG2EI16.V##RISCV" :10,  
    "VLOXSEG2EI32.V##RISCV" :10,  
    "VLOXSEG2EI64.V##RISCV" :10,  
    "VLOXSEG2EI8.V##RISCV"  :10,  
    "VLOXSEG3EI16.V##RISCV" :10,  
    "VLOXSEG3EI32.V##RISCV" :10,  
    "VLOXSEG3EI64.V##RISCV" :10,  
    "VLOXSEG3EI8.V##RISCV"  :10,  
    "VLOXSEG4EI16.V##RISCV" :10,  
    "VLOXSEG4EI32.V##RISCV" :10,  
    "VLOXSEG4EI64.V##RISCV" :10,  
    "VLOXSEG4EI8.V##RISCV"  :10,  
    "VLOXSEG5EI16.V##RISCV" :10,  
    "VLOXSEG5EI32.V##RISCV" :10,  
    "VLOXSEG5EI64.V##RISCV" :10,  
    "VLOXSEG5EI8.V##RISCV"  :10,  
    "VLOXSEG6EI16.V##RISCV" :10,  
    "VLOXSEG6EI32.V##RISCV" :10,  
    "VLOXSEG6EI64.V##RISCV" :10,  
    "VLOXSEG6EI8.V##RISCV"  :10,  
    "VLOXSEG7EI16.V##RISCV" :10,  
    "VLOXSEG7EI32.V##RISCV" :10,  
    "VLOXSEG7EI64.V##RISCV" :10,  
    "VLOXSEG7EI8.V##RISCV"  :10,  
    "VLOXSEG8EI16.V##RISCV" :10,  
    "VLOXSEG8EI32.V##RISCV" :10,  
    "VLOXSEG8EI64.V##RISCV" :10,  
    "VLOXSEG8EI8.V##RISCV"  :10,  
    "VLSE16.V##RISCV"       :10,  
    "VLSE32.V##RISCV"       :10,  
    "VLSE64.V##RISCV"       :10,  
    "VLSE8.V##RISCV"        :10,  
    "VLSEG2E16.V##RISCV"    :10,  
    "VLSEG2E16FF.V##RISCV"  :10,  
    "VLSEG2E32.V##RISCV"    :10,  
    "VLSEG2E32FF.V##RISCV"  :10,  
    "VLSEG2E64.V##RISCV"    :10,  
    "VLSEG2E64FF.V##RISCV"  :10,  
    "VLSEG2E8.V##RISCV"     :10,  
    "VLSEG2E8FF.V##RISCV"   :10,  
    "VLSEG3E16.V##RISCV"    :10,  
    "VLSEG3E16FF.V##RISCV"  :10,  
    "VLSEG3E32.V##RISCV"    :10,  
    "VLSEG3E32FF.V##RISCV"  :10,  
    "VLSEG3E64.V##RISCV"    :10,  
    "VLSEG3E64FF.V##RISCV"  :10,  
    "VLSEG3E8.V##RISCV"     :10,  
    "VLSEG3E8FF.V##RISCV"   :10,  
    "VLSEG4E16.V##RISCV"    :10,  
    "VLSEG4E16FF.V##RISCV"  :10,  
    "VLSEG4E32.V##RISCV"    :10,  
    "VLSEG4E32FF.V##RISCV"  :10,  
    "VLSEG4E64.V##RISCV"    :10,  
    "VLSEG4E64FF.V##RISCV"  :10,  
    "VLSEG4E8.V##RISCV"     :10,  
    "VLSEG4E8FF.V##RISCV"   :10,  
    "VLSEG5E16.V##RISCV"    :10,  
    "VLSEG5E16FF.V##RISCV"  :10,  
    "VLSEG5E32.V##RISCV"    :10,  
    "VLSEG5E32FF.V##RISCV"  :10,  
    "VLSEG5E64.V##RISCV"    :10,  
    "VLSEG5E64FF.V##RISCV"  :10,  
    "VLSEG5E8.V##RISCV"     :10,  
    "VLSEG5E8FF.V##RISCV"   :10,  
    "VLSEG6E16.V##RISCV"    :10,  
    "VLSEG6E16FF.V##RISCV"  :10,  
    "VLSEG6E32.V##RISCV"    :10,  
    "VLSEG6E32FF.V##RISCV"  :10,  
    "VLSEG6E64.V##RISCV"    :10,  
    "VLSEG6E64FF.V##RISCV"  :10,  
    "VLSEG6E8.V##RISCV"     :10,  
    "VLSEG6E8FF.V##RISCV"   :10,  
    "VLSEG7E16.V##RISCV"    :10,  
    "VLSEG7E16FF.V##RISCV"  :10,  
    "VLSEG7E32.V##RISCV"    :10,  
    "VLSEG7E32FF.V##RISCV"  :10,  
    "VLSEG7E64.V##RISCV"    :10,  
    "VLSEG7E64FF.V##RISCV"  :10,  
    "VLSEG7E8.V##RISCV"     :10,  
    "VLSEG7E8FF.V##RISCV"   :10,  
    "VLSEG8E16.V##RISCV"    :10,  
    "VLSEG8E16FF.V##RISCV"  :10,  
    "VLSEG8E32.V##RISCV"    :10,  
    "VLSEG8E32FF.V##RISCV"  :10,  
    "VLSEG8E64.V##RISCV"    :10,  
    "VLSEG8E64FF.V##RISCV"  :10,  
    "VLSEG8E8.V##RISCV"     :10,  
    "VLSEG8E8FF.V##RISCV"   :10,  
    "VLSSEG2E16.V##RISCV"   :10,  
    "VLSSEG2E32.V##RISCV"   :10,  
    "VLSSEG2E64.V##RISCV"   :10,  
    "VLSSEG2E8.V##RISCV"    :10,  
    "VLSSEG3E16.V##RISCV"   :10,  
    "VLSSEG3E32.V##RISCV"   :10,  
    "VLSSEG3E64.V##RISCV"   :10,  
    "VLSSEG3E8.V##RISCV"    :10,  
    "VLSSEG4E16.V##RISCV"   :10,  
    "VLSSEG4E32.V##RISCV"   :10,  
    "VLSSEG4E64.V##RISCV"   :10,  
    "VLSSEG4E8.V##RISCV"    :10,  
    "VLSSEG5E16.V##RISCV"   :10,  
    "VLSSEG5E32.V##RISCV"   :10,  
    "VLSSEG5E64.V##RISCV"   :10,  
    "VLSSEG5E8.V##RISCV"    :10,  
    "VLSSEG6E16.V##RISCV"   :10,  
    "VLSSEG6E32.V##RISCV"   :10,  
    "VLSSEG6E64.V##RISCV"   :10,  
    "VLSSEG6E8.V##RISCV"    :10,  
    "VLSSEG7E16.V##RISCV"   :10,  
    "VLSSEG7E32.V##RISCV"   :10,  
    "VLSSEG7E64.V##RISCV"   :10,  
    "VLSSEG7E8.V##RISCV"    :10,  
    "VLSSEG8E16.V##RISCV"   :10,  
    "VLSSEG8E32.V##RISCV"   :10,  
    "VLSSEG8E64.V##RISCV"   :10,  
    "VLSSEG8E8.V##RISCV"    :10,  
    "VLUXEI16.V##RISCV"     :10,  
    "VLUXEI32.V##RISCV"     :10,  
    "VLUXEI64.V##RISCV"     :10,  
    "VLUXEI8.V##RISCV"      :10,  
    "VLUXSEG2EI16.V##RISCV" :10,  
    "VLUXSEG2EI32.V##RISCV" :10,  
    "VLUXSEG2EI64.V##RISCV" :10,  
    "VLUXSEG2EI8.V##RISCV"  :10,  
    "VLUXSEG3EI16.V##RISCV" :10,  
    "VLUXSEG3EI32.V##RISCV" :10,  
    "VLUXSEG3EI64.V##RISCV" :10,  
    "VLUXSEG3EI8.V##RISCV"  :10,  
    "VLUXSEG4EI16.V##RISCV" :10,  
    "VLUXSEG4EI32.V##RISCV" :10,  
    "VLUXSEG4EI64.V##RISCV" :10,  
    "VLUXSEG4EI8.V##RISCV"  :10,  
    "VLUXSEG5EI16.V##RISCV" :10,  
    "VLUXSEG5EI32.V##RISCV" :10,  
    "VLUXSEG5EI64.V##RISCV" :10,  
    "VLUXSEG5EI8.V##RISCV"  :10,  
    "VLUXSEG6EI16.V##RISCV" :10,  
    "VLUXSEG6EI32.V##RISCV" :10,  
    "VLUXSEG6EI64.V##RISCV" :10,  
    "VLUXSEG6EI8.V##RISCV"  :10,  
    "VLUXSEG7EI16.V##RISCV" :10,  
    "VLUXSEG7EI32.V##RISCV" :10,  
    "VLUXSEG7EI64.V##RISCV" :10,  
    "VLUXSEG7EI8.V##RISCV"  :10,  
    "VLUXSEG8EI16.V##RISCV" :10,  
    "VLUXSEG8EI32.V##RISCV" :10,  
    "VLUXSEG8EI64.V##RISCV" :10,  
    "VLUXSEG8EI8.V##RISCV"  :10,  
}

v_Ld_map = InstructionMap("v_Ld_instructions", v_Ld_instructions)

v_St_instructions = {
    "VS1R.V##RISCV"         :10,  
    "VS2R.V##RISCV"         :10,  
    "VS4R.V##RISCV"         :10,  
    "VS8R.V##RISCV"         :10,  
    "VSE16.V##RISCV"        :10,  
    "VSE32.V##RISCV"        :10,  
    "VSE64.V##RISCV"        :10,  
    "VSE8.V##RISCV"         :10,  
    "VSM.V##RISCV"          :10,  
    "VSOXEI16.V##RISCV"     :10,  
    "VSOXEI32.V##RISCV"     :10,  
    "VSOXEI64.V##RISCV"     :10,  
    "VSOXEI8.V##RISCV"      :10,  
    "VSOXSEG2EI16.V##RISCV" :10,  
    "VSOXSEG2EI32.V##RISCV" :10,  
    "VSOXSEG2EI64.V##RISCV" :10,  
    "VSOXSEG2EI8.V##RISCV"  :10,  
    "VSOXSEG3EI16.V##RISCV" :10,  
    "VSOXSEG3EI32.V##RISCV" :10,  
    "VSOXSEG3EI64.V##RISCV" :10,  
    "VSOXSEG3EI8.V##RISCV"  :10,  
    "VSOXSEG4EI16.V##RISCV" :10,  
    "VSOXSEG4EI32.V##RISCV" :10,  
    "VSOXSEG4EI64.V##RISCV" :10,  
    "VSOXSEG4EI8.V##RISCV"  :10,  
    "VSOXSEG5EI16.V##RISCV" :10,  
    "VSOXSEG5EI32.V##RISCV" :10,  
    "VSOXSEG5EI64.V##RISCV" :10,  
    "VSOXSEG5EI8.V##RISCV"  :10,  
    "VSOXSEG6EI16.V##RISCV" :10,  
    "VSOXSEG6EI32.V##RISCV" :10,  
    "VSOXSEG6EI64.V##RISCV" :10,  
    "VSOXSEG6EI8.V##RISCV"  :10,  
    "VSOXSEG7EI16.V##RISCV" :10,  
    "VSOXSEG7EI32.V##RISCV" :10,  
    "VSOXSEG7EI64.V##RISCV" :10,  
    "VSOXSEG7EI8.V##RISCV"  :10,  
    "VSOXSEG8EI16.V##RISCV" :10,  
    "VSOXSEG8EI32.V##RISCV" :10,  
    "VSOXSEG8EI64.V##RISCV" :10,  
    "VSOXSEG8EI8.V##RISCV"  :10,  
    "VSSE16.V##RISCV"       :10,  
    "VSSE32.V##RISCV"       :10,  
    "VSSE64.V##RISCV"       :10,  
    "VSSE8.V##RISCV"        :10,  
    "VSSEG2E16.V##RISCV"    :10,  
    "VSSEG2E32.V##RISCV"    :10,  
    "VSSEG2E64.V##RISCV"    :10,  
    "VSSEG2E8.V##RISCV"     :10,  
    "VSSEG3E16.V##RISCV"    :10,  
    "VSSEG3E32.V##RISCV"    :10,  
    "VSSEG3E64.V##RISCV"    :10,  
    "VSSEG3E8.V##RISCV"     :10,  
    "VSSEG4E16.V##RISCV"    :10,  
    "VSSEG4E32.V##RISCV"    :10,  
    "VSSEG4E64.V##RISCV"    :10,  
    "VSSEG4E8.V##RISCV"     :10,  
    "VSSEG5E16.V##RISCV"    :10,  
    "VSSEG5E32.V##RISCV"    :10,  
    "VSSEG5E64.V##RISCV"    :10,  
    "VSSEG5E8.V##RISCV"     :10,  
    "VSSEG6E16.V##RISCV"    :10,  
    "VSSEG6E32.V##RISCV"    :10,  
    "VSSEG6E64.V##RISCV"    :10,  
    "VSSEG6E8.V##RISCV"     :10,  
    "VSSEG7E16.V##RISCV"    :10,  
    "VSSEG7E32.V##RISCV"    :10,  
    "VSSEG7E64.V##RISCV"    :10,  
    "VSSEG7E8.V##RISCV"     :10,  
    "VSSEG8E16.V##RISCV"    :10,  
    "VSSEG8E32.V##RISCV"    :10,  
    "VSSEG8E64.V##RISCV"    :10,  
    "VSSEG8E8.V##RISCV"     :10,  
    "VSSSEG2E16.V##RISCV"   :10,  
    "VSSSEG2E32.V##RISCV"   :10,  
    "VSSSEG2E64.V##RISCV"   :10,  
    "VSSSEG2E8.V##RISCV"    :10,  
    "VSSSEG3E16.V##RISCV"   :10,  
    "VSSSEG3E32.V##RISCV"   :10,  
    "VSSSEG3E64.V##RISCV"   :10,  
    "VSSSEG3E8.V##RISCV"    :10,  
    "VSSSEG4E16.V##RISCV"   :10,  
    "VSSSEG4E32.V##RISCV"   :10,  
    "VSSSEG4E64.V##RISCV"   :10,  
    "VSSSEG4E8.V##RISCV"    :10,  
    "VSSSEG5E16.V##RISCV"   :10,  
    "VSSSEG5E32.V##RISCV"   :10,  
    "VSSSEG5E64.V##RISCV"   :10,  
    "VSSSEG5E8.V##RISCV"    :10,  
    "VSSSEG6E16.V##RISCV"   :10,  
    "VSSSEG6E32.V##RISCV"   :10,  
    "VSSSEG6E64.V##RISCV"   :10,  
    "VSSSEG6E8.V##RISCV"    :10,  
    "VSSSEG7E16.V##RISCV"   :10,  
    "VSSSEG7E32.V##RISCV"   :10,  
    "VSSSEG7E64.V##RISCV"   :10,  
    "VSSSEG7E8.V##RISCV"    :10,  
    "VSSSEG8E16.V##RISCV"   :10,  
    "VSSSEG8E32.V##RISCV"   :10,  
    "VSSSEG8E64.V##RISCV"   :10,  
    "VSSSEG8E8.V##RISCV"    :10,  
    "VSUXEI16.V##RISCV"     :10,  
    "VSUXEI32.V##RISCV"     :10,  
    "VSUXEI64.V##RISCV"     :10,  
    "VSUXEI8.V##RISCV"      :10,  
    "VSUXSEG2EI16.V##RISCV" :10,  
    "VSUXSEG2EI32.V##RISCV" :10,  
    "VSUXSEG2EI64.V##RISCV" :10,  
    "VSUXSEG2EI8.V##RISCV"  :10,  
    "VSUXSEG3EI16.V##RISCV" :10,  
    "VSUXSEG3EI32.V##RISCV" :10,  
    "VSUXSEG3EI64.V##RISCV" :10,  
    "VSUXSEG3EI8.V##RISCV"  :10,  
    "VSUXSEG4EI16.V##RISCV" :10,  
    "VSUXSEG4EI32.V##RISCV" :10,  
    "VSUXSEG4EI64.V##RISCV" :10,  
    "VSUXSEG4EI8.V##RISCV"  :10,  
    "VSUXSEG5EI16.V##RISCV" :10,  
    "VSUXSEG5EI32.V##RISCV" :10,  
    "VSUXSEG5EI64.V##RISCV" :10,  
    "VSUXSEG5EI8.V##RISCV"  :10,  
    "VSUXSEG6EI16.V##RISCV" :10,  
    "VSUXSEG6EI32.V##RISCV" :10,  
    "VSUXSEG6EI64.V##RISCV" :10,  
    "VSUXSEG6EI8.V##RISCV"  :10,  
    "VSUXSEG7EI16.V##RISCV" :10,  
    "VSUXSEG7EI32.V##RISCV" :10,  
    "VSUXSEG7EI64.V##RISCV" :10,  
    "VSUXSEG7EI8.V##RISCV"  :10,  
    "VSUXSEG8EI16.V##RISCV" :10,  
    "VSUXSEG8EI32.V##RISCV" :10,  
    "VSUXSEG8EI64.V##RISCV" :10,  
    "VSUXSEG8EI8.V##RISCV"  :10,
}

v_St_map = InstructionMap("v_St_instructions", v_St_instructions)

vector_none_ldst_instructions = merge(
    vinteger_instructions,
    vfixed_point_instructions,
    vfloating_point_instructions,
    vreduction_instructions,
    vmask_instructions,
    vpermutation_instructions,
    vbasic_BitManipulation_instructions,
    #Zvediv_instructions
)

vector_none_ldst_map = InstructionMap("vector_none_ldst_instructions", vector_none_ldst_instructions)

vector_All_instructions = merge(
     vldst_instructions,
     vinteger_instructions,
     vfixed_point_instructions,
     vfloating_point_instructions,
     vreduction_instructions,
     vmask_instructions,
     vpermutation_instructions,
     vbasic_BitManipulation_instructions,
    #Zvediv_instructions
)

vector_All_map = InstructionMap("vector_All_instructions", vector_All_instructions)
